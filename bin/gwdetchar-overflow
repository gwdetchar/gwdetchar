#!/usr/bin/env python
# coding=utf-8
# Copyright (C) LIGO Scientific Collaboration (2015-)
#
# This file is part of the GW DetChar python package.
#
# GW DetChar is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# GW DetChar is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with GW DetChar.  If not, see <http://www.gnu.org/licenses/>.

"""Find overflows associated with a particular front-end model
"""

from __future__ import print_function

import numpy
import os.path
import sys

from matplotlib import use
use('agg')

from glue.ligolw.utils import write_fileobj

from gwpy.segments import (DataQualityFlag, DataQualityDict,
                           Segment, SegmentList)
from gwpy.timeseries import (TimeSeries, TimeSeriesDict)
from gwpy.io.cache import cache_segments
from gwpy.utils import gprint

from gwdetchar import (cds, cli, const, daq, __version__)
from gwdetchar.io import (datafind, ligolw, html as htmlio)

__author__ = 'TJ Massinger <thomas.massinger@ligo.org>'
__credits__ = 'Duncan Macleod <duncan.macleod@ligo.org>'


def plot_overflows(flag, span, facecolor='red', edgecolor='darkred',
                   known={'alpha': 0.1, 'facecolor': 'lightgray'}):
    """Plot the overflow segments contained within this flag
    """
    plot = flag.plot(figsize=[12, 2], facecolor=facecolor, edgecolor=edgecolor,
                     known=known, label=' ')
    plot.subplots_adjust(bottom=0.4, top=0.8)
    plot.set_title('%s segments' % flag.name.replace('_', r'\_'))
    plot.set_xlim(*span)
    plot.set_epoch(span[0])
    return plot


def table_from_times(times, channel):
    return ligolw.sngl_burst_from_times(
        times, snr=10, peak_frequency=100, channel=channel,
        search=os.path.basename(__file__))


def get_real_channel(adcchannel):
    main = str(adcchannel).split('-', 1)[1]
    ifo = str(adcchannel).split(':')[0]
    dcuid, type_, _, _, card, slot = main.split('_')
    if type_ != 'ADC':
        raise ValueError("No 'real' channel map for non-ADC channels")
    modelname = cds.model_name_from_dcuid(ifo, int(dcuid))
    return cds.get_adc_channel(ifo, modelname, int(card), int(slot))


parser = cli.create_parser(description=__doc__)
cli.add_gps_start_stop_arguments(parser)
cli.add_ifo_option(parser)
parser.add_argument('dcuid', type=int, nargs='+',
                    help='DCUID for the relevant front-end model')
cli.add_frametype_option(parser, required=const.IFO is None,
                         default=const.IFO is not None and '%s_R' % const.IFO)
cli.add_nproc_option(parser)
parser.add_argument('--deep', action='store_true', default=False,
                    help='perform deep scan, default: %(default)s')
parser.add_argument('-a', '--state-flag', metavar='FLAG',
                    help='restrict search to times when FLAG was active')
parser.add_argument('-o', '--output-file',
                    help='path to output xml file, default name will be '
                         'automatically generated based on IFO and GPS times')
parser.add_argument('-O', '--output-format', default='sngl_burst',
                    choices=['sngl_burst', 'segments', 'integer-segments'],
                    help='output format, default: %(default)s')
parser.add_argument('-p', '--segment-pad', type=float, default=0.1,
                    help='minimum padding (one-sided) for output segments '
                         'when using --output-format '
                         '[segments|integer-segments]')
parser.add_argument('-s', '--segment-end-pad', type=float, default=1.0,
                    help='amount of time to remove from the end of each '
                         'analysis segment')
parser.add_argument('-m', '--html', help='path to write html output')
parser.add_argument('-v', '--plot', action='store_true', default=None,
                    help='make plots of all overflows, defaul: %(default)s')
parser.add_argument('-c', '--fec-map', help='URL of human-readable FEC map')

args = parser.parse_args()

span = Segment(args.gpsstart, args.gpsend)

# get segments
if args.state_flag:
    state = DataQualityFlag.query(args.state_flag, int(args.gpsstart),
                                  int(args.gpsend),
                                  url=const.O1_SEGMENT_SERVER)
    tmp = type(state.active)()
    for i, seg in enumerate(state.active):
        if abs(seg) < args.segment_end_pad:
            continue
        tmp.append(type(seg)(seg[0], seg[1]-args.segment_end_pad))
    state.active = tmp.coalesce()
    statea = state.active
else:
    statea = SegmentList([span])

if not args.output_file:
    duration = abs(span)
    args.output_file = (
        '%s-OVERFLOWS-%d-%d.xml.gz'
        % (args.ifo, int(args.gpsstart), duration))
    gprint("Set default output file as %s" % args.output_file)

# get frame cache
cache = datafind.find_frames(args.ifo[0], args.frametype,
                             int(args.gpsstart), int(args.gpsend))
cachesegs = statea & cache_segments(cache)

# set up container
if args.output_format.endswith('segments'):
    use_segments = True
    overflows = DataQualityDict()
    def find_overflows(timeseries, channel, segment):
        segs = daq.find_overflow_segments(timeseries)
        segs.known &= SegmentList([segment])
        segs.coalesce()
        try:
            overflows[channel] += segs
        except KeyError:
            overflows[channel] = segs
else:
    use_segments = False
    overflows = ligolw.new_table(
        'sngl_burst',
        columns=['peak_time', 'peak_time_ns', 'event_id', 'channel', 'snr'])
    def find_overflows(timeseries, channel, segment):
        times = daq.find_overflows(timeseries)
        times = times[(times >= float(segment[0])) &
                      (times < float(segment[1]))]
        overflows.extend(table_from_times(times, channel))

# get channel and find overflows
for dcuid in args.dcuid:
    gprint("Processing DCUID %d" % dcuid)
    channel = daq.ligo_accum_overflow_channel(dcuid, args.ifo)
    if args.deep:
        gprint("    Getting list of overflow channels...", end=' ')
        try:
            channels = daq.ligo_model_overflow_channels(
                dcuid, args.ifo, args.frametype, gpstime=span[0])
        except IndexError:  # no frame found for GPS start, try GPS end
            channels = daq.ligo_model_overflow_channels(
                dcuid, args.ifo, args.frametype, gpstime=span[-1])
        gprint("    %d channels found" % len(channel))
    for seg in cachesegs:
        c = cache.sieve(segment=seg)
        gprint("    Reading ACCUM_OVERFLOW data for %d-%d..." % seg, end=' ')
        data = TimeSeries.read(c, channel, nproc=args.nproc,
                               start=seg[0], end=seg[1])
        if use_segments:
            new = daq.find_overflow_segments(data)
            osegs = type(new.active)([type(s)(s[0]-2, s[0]+2) for
                                      s in new.active])
            go_deep = len(new.active) > 0
        else:
            new = daq.find_overflows(data)
            osegs = SegmentList([Segment(t-2, t+2) for t in new])
            go_deep = new.size != 0
        gprint("%d overflows found" % len(osegs))
        if args.deep:
            if go_deep:
                gprint("    Going deep...", end=' ')
                for s, e in osegs.coalesce():
                    data = TimeSeriesDict.read(c, channels, nproc=args.nproc,
                                               start=s, end=e)
                    for ch in channels:
                        find_overflows(data[ch], ch, seg)
                gprint("Done")
            else:
                for ch in channels:
                    try:
                        overflows[ch] += DataQualityFlag(ch, known=[seg])
                    except KeyError:
                        overflows[ch] = DataQualityFlag(ch, known=[seg])
        elif not args.deep and use_segments:
            try:
                overflows[channel] += new
            except KeyError:
                overflows[channel] = new
        elif not args.deep:
            overflows.extend(table_from_times(new, channel))
    gprint("    Complete")

# get segments
if use_segments:
    for flag in overflows:
        overflows[flag].known = cachesegs
    segs = overflows
else:
    segs = ligolw.segments_from_sngl_burst(
        overflows, args.segment_pad, known=statea)
if args.output_format == 'integer-segments':
    for key in segs:
        segs[key] = segs[key].round()

# write results to file
file = open(args.output_file, 'w')
gz = args.output_file.endswith('.gz')
if args.output_format == 'sngl_burst':
    write_fileobj(ligolw.table_to_document(overflows), file, gz=gz)
else:
    segs.write(file, format='ligolw', gz=gz)
gprint("Written output to %s" % args.output_file)

# write HTML
if args.html:
    if args.plot:
        args.plot = os.path.dirname(args.html)
    if args.output_file:
        args.output_file = os.path.relpath(
            args.output_file, os.path.dirname(args.html))
    if os.path.basename(args.html) == 'index.html':
        page = htmlio.new_bootstrap_page(
            title='%s Overflows: %d-%d' % (
                args.ifo, int(args.gpsstart), int(args.gpsend)))
    else:
        page = htmlio.markup.page()
    page.div(class_='container')

    # -- header
    page.div(class_='page-header')
    page.h1('%s ADC/DAC Overflows: %d-%d'
            % (args.ifo, int(args.gpsstart), int(args.gpsend)))
    page.p("This analysis searched for digital-to-analogue (DAC) or "
           "analogue-to-digital (ADC) conversion overflows in the LIGO "
           "real-time controls system.")
    if args.deep:
        page.p("A hierarchichal search was performed, with a single "
               "cumulative overflow counter checked per front-end controller "
               "(FEC); for those models that indicate an overflow, the "
               "card/slot-specific channels were then checked.")
    page.div.close()

    # -- segments
    page.h2('Segments')
    # link XML file
    if args.output_file:
        page.p()
        page.add('The full output segments are recorded in here:')
        page.a(os.path.basename(args.output_file), href=args.output_file,
               target='_blank')
        page.p.close()
    # print state segments
    if args.state_flag:
        page.p('This analysis was executed over the following segments:')
        page.div(class_='panel-group', id_='accordion1')
        page.add(str(htmlio.write_flag_html(
            state, span, 'state', parent='accordion1', context='success')))
        page.div.close()
    # print overflow segments
    if sum(abs(s.active) for s in segs.values()):
        page.p('The following channels indicated an overflow (constant overflow is yellow, otherwise red):')
        page.div(class_='panel-group', id_='accordion2')
        for i, (c, flag) in enumerate(segs.iteritems()):
            if abs(flag.active) == 0:
                continue
            if abs(flag.active) == abs(cachesegs):
                context = 'warning'
            else:
                context = 'danger'
            try:
                channel = get_real_channel(flag.name)
            except Exception:
                title = '%s [%d]' % (flag.name, len(flag.active))
            else:
                title = '%s (%s) [%d]' % (flag.name, channel, len(flag.active))
            page.add(str(htmlio.write_flag_html(
                flag, span, i, parent='accordion2', title=title,
                context=context, plotdir=args.plot, plot_func=plot_overflows)))
        page.div.close()
    else:
        page.div(class_='alert alert-info')
        page.p('No overflows were found')
        page.div.close()

    # -- results table
    page.h2('Results summary')
    page.table(class_='table table-striped table-hover')
    # write table header
    page.thead()
    page.tr()
    for header in ['Channel', 'Connected signal', 'Num. overflows']:
        page.th(header)
    page.thead.close()
    # write body
    page.tbody()
    for c, seglist in segs.iteritems():
        t = abs(seglist.active)
        if t == 0:
            context = 'default'
        elif t == abs(cachesegs):
            context = 'warning'
        else:
            context = 'danger'
        page.tr(class_=context)
        page.td(c)
        try:
            page.td(get_real_channel(str(c)))
        except Exception:
            page.td()
        page.td(len(seglist.active))
        page.tr.close()
    page.tbody.close()
    page.table.close()

    # -- paramters
    page.h2('Parameters')
    page.p('This analysis used the following parameters:')
    def write_param(param, value):
        page.p()
        page.strong('%s: ' % param)
        page.add(str(value))
        page.p.close()
    write_param('Start time', args.gpsstart)
    write_param('End time', args.gpsend)
    write_param('State flag', args.state_flag)
    write_param('DCUIDs', ' '.join(map(str, args.dcuid)))

    if args.fec_map:
        page.h2('Links')
        write_param('FEC map', '<a href="{0}" target="_blank" title="{1} FEC '
                               'map">{0}</a>'.format(args.fec_map, args.ifo))

    # -- close and write
    page.div.close()
    with open(args.html, 'w') as fp:
        print(str(page), file=fp)
    gprint("HTML written to %s" % args.html)
